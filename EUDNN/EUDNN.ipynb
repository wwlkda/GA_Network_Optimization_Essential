{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import svm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader,sampler\n",
    "import torchvision\n",
    "\n",
    "from scipy.linalg import qr,null_space\n",
    "import math\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", module=\"sklearn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset=torchvision.datasets.MNIST(root='./data/mnist',train=True,\n",
    "                                         transform=torchvision.transforms.ToTensor(),download=True)\n",
    "test_dataset=torchvision.datasets.MNIST(root='./data/mnist',train=False,\n",
    "                                         transform=torchvision.transforms.ToTensor(),download=True)\n",
    "x_train=train_dataset.data\n",
    "y_train=train_dataset.targets\n",
    "x_test=test_dataset.data\n",
    "y_test=test_dataset.targets\n",
    "\n",
    "x_train=x_train.view(60000,-1)\n",
    "x_test=x_test.view(10000,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Generate_Orthogonal(n):\n",
    "    H = np.random.randn(n, n)\n",
    "    Q,_= qr(H)\n",
    "    return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Solving_Equation(n,Q,b):\n",
    "    a1=np.matmul(Q,b)\n",
    "    a=np.zeros([n,n])\n",
    "    a[0,:]=a1\n",
    "    return a1,null_space(a).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoding(n):\n",
    "    b=np.random.randn(n)\n",
    "    \n",
    "    chrome=np.zeros(2*n+1)\n",
    "    chrome[:n]=b\n",
    "    chrome[n:2*n-1]=np.random.randint(low=0,high=2,size=(n-1))\n",
    "    \n",
    "    num=np.random.randint(1,4)\n",
    "    if num>=2:\n",
    "        chrome[2*n-1]=1\n",
    "    if num!=2:\n",
    "        chrome[2*n]=1\n",
    "    \n",
    "    return chrome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    0     1     2 ... 59997 59998 59999]\n"
     ]
    }
   ],
   "source": [
    "M=50\n",
    "G=20\n",
    "Rho=0.9\n",
    "Mu=0.1\n",
    "IniN=785\n",
    "MaxLayer=5\n",
    "MiniBatch=100\n",
    "\n",
    "net=nn.Sequential()\n",
    "\n",
    "#两个序列用于后面随机采样用\n",
    "Seq_train=np.array(range(len(train_dataset)))\n",
    "Seq_test=np.array(range(len(test_dataset)))\n",
    "\n",
    "print(Seq_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decode(group,chrome):\n",
    "    n=group.n\n",
    "    b=chrome[0:n]\n",
    "    a1,a_remain=Solving_Equation(n,group.Q,b)\n",
    "    a=np.row_stack((a1,a_remain))\n",
    "    arch=np.nonzero(chrome[n:2*n-1])\n",
    "    arch=np.squeeze(arch)\n",
    "    \n",
    "    w=np.zeros((len(arch),group.n-1))\n",
    "    b=np.zeros(len(arch))\n",
    "    for i in range(len(arch)):\n",
    "        w[i,:]=a[arch[i],:-1]\n",
    "        b[i]=a[arch[i],-1]\n",
    "    act=chrome[2*n-1:2*n+1]\n",
    "    \n",
    "    activation=None\n",
    "    if act[0]==1:\n",
    "        if act[1]==1:\n",
    "            activation=torch.relu\n",
    "        else: \n",
    "            activation=torch.sigmoid\n",
    "    else:\n",
    "        activation=torch.tanh\n",
    "    \n",
    "    return w,b,activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Group:\n",
    "    def __init__(self,n,layer):\n",
    "        self.layer=layer\n",
    "        self.data=np.array([Encoding(n) for i in range(M)])\n",
    "        self.Q=Generate_Orthogonal(n)\n",
    "        self.n=n\n",
    "        self.fitness=np.zeros(len(self.data))\n",
    "        self.dataQ=np.array([]) \n",
    "        self.fitnessQ=np.zeros(len(self.data))\n",
    "        \n",
    "        self.fitness_elit=0\n",
    "        self.data_elit=np.zeros(len(self.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ind_Evaluate(group,chrome,serial_train,serial_test,pre_represent_train,pre_represent_test): \n",
    "    w,b,activation=Decode(group,chrome)\n",
    "    \n",
    "    past_represent_train=np.matmul(pre_represent_train,w.T)+b\n",
    "    past_represent_test=np.matmul(pre_represent_test,w.T)+b\n",
    "    \n",
    "    past_represent_train=torch.Tensor(past_represent_train)\n",
    "    past_represent_test=torch.Tensor(past_represent_test)\n",
    "    \n",
    "    past_represent_train=activation(past_represent_train).numpy()\n",
    "    past_represent_test=activation(past_represent_test).numpy()\n",
    "    \n",
    "    predictor = svm.SVC(kernel='linear',max_iter=5000)\n",
    "    predictor.fit(past_represent_train, [y_train[i] for i in serial_train])\n",
    "    \n",
    "    result = np.array(predictor.predict(past_represent_test))\n",
    "    accuracy = np.sum(np.equal(result, [y_test[i] for i in serial_test])) / len(serial_test)\n",
    "    \n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor([[1,2],[3,4]]).numpy()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Group_Evaluate(group,aim):\n",
    "    \n",
    "    np.random.shuffle(Seq_train)\n",
    "    serial_train = Seq_train[0:1000]\n",
    "    \n",
    "    np.random.shuffle(Seq_test)\n",
    "    serial_test = Seq_test[0:1000]\n",
    "    \n",
    "    if group.layer>1:\n",
    "            \n",
    "        pre_represent_train=net(torch.Tensor([x_train[i].numpy().tolist() for i in serial_train]))\n",
    "        pre_represent_train=pre_represent_train.detach().numpy()\n",
    "        \n",
    "        pre_represent_test=net(torch.Tensor([x_test[i].numpy().tolist() for i in serial_test]))\n",
    "        pre_represent_test=pre_represent_test.detach().numpy()\n",
    "    else:\n",
    "        pre_represent_train=np.array([x_train[i].numpy() for i in serial_train])\n",
    "        pre_represent_test=np.array([x_test[i].numpy() for i in serial_test])\n",
    "    \n",
    "    temp=0\n",
    "    if aim=='P':\n",
    "        for ind in group.data:\n",
    "            group.fitness[temp]=Ind_Evaluate(group,ind,\n",
    "                                             serial_train,serial_test,pre_represent_train,pre_represent_test)\n",
    "            temp+=1\n",
    "    elif aim=='Q':\n",
    "        for ind in group.dataQ:\n",
    "            group.fitnessQ[temp]=Ind_Evaluate(group,ind,\n",
    "                                              serial_train,serial_test,pre_represent_train,pre_represent_test)\n",
    "            temp+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_tour(group):\n",
    "    index=np.random.choice(M,size=2)\n",
    "    if group.fitness[index[0]]>group.fitness[index[1]]:\n",
    "        return group.data[index[0]]\n",
    "    else:\n",
    "        return group.data[index[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_tour_Together(group):\n",
    "    index=np.random.choice(2*M,size=2)\n",
    "    if group.fitnessQ[index[0]]>group.fitnessQ[index[1]]:\n",
    "        return index[0]\n",
    "    else:\n",
    "        return index[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sibling(group):\n",
    "    ind1=bin_tour(group)\n",
    "    ind2=bin_tour(group)\n",
    "    if np.random.uniform(0,1)<Rho :\n",
    "        l1=2*group.n-1\n",
    "        l2=2\n",
    "        \n",
    "        i1=np.random.randint(0,l1)\n",
    "        i2=np.random.randint(0,l2)\n",
    "        \n",
    "        ind1[i1:l1],ind2[i1:l1]=ind2[i1:l1],ind1[i1:l1]\n",
    "        ind1[l1:l1+i2],ind2[l1:l1+i2]=ind2[l1:l1+i2],ind1[l1:l1+i2]\n",
    "        \n",
    "        if ind1[l1]==0 and ind1[l1+1]==0:\n",
    "            num=np.random.randint(1,4)\n",
    "            if num>=2:\n",
    "                ind1[l1]=1\n",
    "            if num!=2:\n",
    "                ind1[l1+1]=1\n",
    "        if ind2[l1]==0 and ind2[l1+1]==0:\n",
    "            num=np.random.randint(1,4)\n",
    "            if num>=2:\n",
    "                ind2[l1]=1\n",
    "            if num!=2:\n",
    "                ind2[l1+1]=1       \n",
    "                \n",
    "    return ind1,ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SemiPolyMutate(group):\n",
    "    Itam=20 #分布指数\n",
    "    for index,ind in enumerate(group.dataQ):\n",
    "        if np.random.uniform(0,1)<Mu:\n",
    "            \n",
    "            for i in range(len(ind)):\n",
    "                ui=np.random.uniform(0,1)\n",
    "                if ui<0.5:\n",
    "                    group.dataQ[index][i]+=math.pow(2*ui,1/(Itam+1))-1\n",
    "                    \n",
    "                    #二进制位变异没有找到文章对应描述，故做如下处理。\n",
    "                    if i>=group.n and group.dataQ[index][i]<0:\n",
    "                        group.dataQ[index][i]=0\n",
    "                    else:\n",
    "                        group.dataQ[index][i]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Operator_Handler(group):\n",
    "    i=0\n",
    "    listQ=[]\n",
    "    while i<M:\n",
    "        i+=2\n",
    "        ind1,ind2=Sibling(group)\n",
    "        listQ.append(ind1)\n",
    "        listQ.append(ind2)\n",
    "          \n",
    "    group.dataQ=np.array(listQ)\n",
    "    \n",
    "    SemiPolyMutate(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Select_Together(group):\n",
    "    group.dataQ=np.row_stack([group.data,group.dataQ])\n",
    "    group.fitnessQ=np.concatenate([group.fitness,group.fitnessQ])\n",
    "\n",
    "    index=np.argmax(group.fitnessQ)\n",
    "    \n",
    "    group.fitness_elit=group.fitnessQ[index]\n",
    "    group.data_elit=group.dataQ[index]\n",
    "    \n",
    "    i=1\n",
    "    listP=[]\n",
    "    listP.append(group.data_elit)\n",
    "    listPfitness=[]\n",
    "    listPfitness.append(group.fitness_elit)\n",
    "    \n",
    "    while i<M:\n",
    "        i+=1\n",
    "        serial=bin_tour_Together(group)\n",
    "        listP.append(group.dataQ[serial])\n",
    "        listPfitness.append(group.fitnessQ[serial])\n",
    "        \n",
    "    group.data=np.array(listP)\n",
    "    group.fitness=np.array(listPfitness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def New_Layer(group):\n",
    "    w,b,activation=Decode(group,group.data_elit)\n",
    "    \n",
    "    if activation==torch.sigmoid: activation=nn.Sigmoid\n",
    "    elif activation==torch.tanh: activation=nn.Tanh\n",
    "    elif activation==torch.relu: activation=nn.ReLU\n",
    "    \n",
    "    name_nn=\"Dense\"+str(group.layer)\n",
    "    name_act=\"Activation\"+str(group.layer)\n",
    "    \n",
    "    net.add_module(name_nn,nn.Linear(group.n-1,np.shape(w)[0]))\n",
    "    net.add_module(name_act,activation())  \n",
    "    print(net)\n",
    "    #装载参数\n",
    "    layer_update=(group.layer-1)*2\n",
    "    net[layer_update].bias.requires_grad=False\n",
    "    net[layer_update].weight.requires_grad=False\n",
    "    \n",
    "    net[layer_update].weight.data=torch.Tensor(w)\n",
    "    net[layer_update].bias.data=torch.Tensor(b)\n",
    "    \n",
    "    net[layer_update].bias.requires_grad=True\n",
    "    net[layer_update].weight.requires_grad=True\n",
    "    \n",
    "    #更新编码长度单位\n",
    "    return np.shape(w)[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Batch_BP(img,label,criterion,optimizer):\n",
    "    \n",
    "    out=net(img)\n",
    "\n",
    "    loss=criterion(out,label)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fine_Tuning(n):\n",
    "    net.add_module(\"classifier\",nn.Linear(n-1,10))\n",
    "    net.add_module(\"softmax\",nn.Softmax(dim=1))\n",
    "    print(net)\n",
    "    \n",
    "    criterion=nn.CrossEntropyLoss()\n",
    "    optimizer=torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "    \n",
    "    for epoch in range(1,21):\n",
    "        train_loss=0\n",
    "        train_loader=DataLoader(dataset=train_dataset,batch_size=MiniBatch)\n",
    "        for img,label in train_loader:\n",
    "            \n",
    "            img=img.view(MiniBatch, -1)\n",
    "            train_loss+=Batch_BP(img,label,criterion,optimizer)\n",
    "            \n",
    "        train_loss/=len(train_loader)\n",
    "        print('BP epoch: {}, Train Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCR_Evaluate():\n",
    "    test_loader=DataLoader(dataset=test_dataset,batch_size=MiniBatch,shuffle=True)\n",
    "    \n",
    "    total=0\n",
    "    correct=0\n",
    "    \n",
    "    for images,labels in test_loader:\n",
    "        images=images.view(MiniBatch,-1)\n",
    "        labels=labels\n",
    "        \n",
    "        out=net(images)\n",
    "        _,predicts=torch.max(out.data,1)\n",
    "        total+=labels.size(0)\n",
    "        correct+=(predicts==labels).sum()\n",
    "    accuracy=100*correct/total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated P\n",
      "generation 1\n",
      "0.88\n",
      "Sequential(\n",
      "  (Dense1): Linear(in_features=784, out_features=376, bias=True)\n",
      "  (Activation1): ReLU()\n",
      ")\n",
      "Evaluated P\n",
      "generation 1\n",
      "0.86\n",
      "Sequential(\n",
      "  (Dense1): Linear(in_features=784, out_features=376, bias=True)\n",
      "  (Activation1): ReLU()\n",
      "  (Dense2): Linear(in_features=376, out_features=203, bias=True)\n",
      "  (Activation2): ReLU()\n",
      ")\n",
      "Evaluated P\n",
      "generation 1\n",
      "0.82\n",
      "Sequential(\n",
      "  (Dense1): Linear(in_features=784, out_features=376, bias=True)\n",
      "  (Activation1): ReLU()\n",
      "  (Dense2): Linear(in_features=376, out_features=203, bias=True)\n",
      "  (Activation2): ReLU()\n",
      "  (Dense3): Linear(in_features=203, out_features=110, bias=True)\n",
      "  (Activation3): ReLU()\n",
      ")\n",
      "Evaluated P\n",
      "generation 1\n",
      "0.739\n",
      "Sequential(\n",
      "  (Dense1): Linear(in_features=784, out_features=376, bias=True)\n",
      "  (Activation1): ReLU()\n",
      "  (Dense2): Linear(in_features=376, out_features=203, bias=True)\n",
      "  (Activation2): ReLU()\n",
      "  (Dense3): Linear(in_features=203, out_features=110, bias=True)\n",
      "  (Activation3): ReLU()\n",
      "  (Dense4): Linear(in_features=110, out_features=62, bias=True)\n",
      "  (Activation4): ReLU()\n",
      ")\n",
      "Sequential(\n",
      "  (Dense1): Linear(in_features=784, out_features=376, bias=True)\n",
      "  (Activation1): ReLU()\n",
      "  (Dense2): Linear(in_features=376, out_features=203, bias=True)\n",
      "  (Activation2): ReLU()\n",
      "  (Dense3): Linear(in_features=203, out_features=110, bias=True)\n",
      "  (Activation3): ReLU()\n",
      "  (Dense4): Linear(in_features=110, out_features=62, bias=True)\n",
      "  (Activation4): ReLU()\n",
      "  (classifier): Linear(in_features=62, out_features=10, bias=True)\n",
      "  (softmax): Softmax(dim=1)\n",
      ")\n",
      "BP epoch: 0, Train Loss: 1.811478\n",
      "BP epoch: 1, Train Loss: 1.641424\n",
      "BP epoch: 2, Train Loss: 1.626579\n",
      "BP epoch: 3, Train Loss: 1.618239\n",
      "BP epoch: 4, Train Loss: 1.612661\n",
      "BP epoch: 5, Train Loss: 1.608156\n",
      "BP epoch: 6, Train Loss: 1.604341\n",
      "BP epoch: 7, Train Loss: 1.600874\n",
      "BP epoch: 8, Train Loss: 1.597837\n",
      "BP epoch: 9, Train Loss: 1.594911\n",
      "tensor(86.2100)\n"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "    n=IniN\n",
    "\n",
    "    for layer in range(1,MaxLayer):\n",
    "        group=Group(n,layer)\n",
    "        Group_Evaluate(group,'P')\n",
    "        print(\"Evaluated P\")\n",
    "        \n",
    "        for generation in range(1,G+1):\n",
    "            print(\"generation\",generation)\n",
    "            \n",
    "            Operator_Handler(group) #Update Q\n",
    "            \n",
    "            Group_Evaluate(group,'Q')\n",
    "            \n",
    "            Select_Together(group) #Update P and elit, modified Q\n",
    "            print(group.fitness_elit)\n",
    "            \n",
    "        n=New_Layer(group)\n",
    "    \n",
    "    Fine_Tuning(n)\n",
    "    print(\"Eventual Accuracy is \",CCR_Evaluate())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "da261d0780e93bc3d36c3a39c2e49d7a3bd7850c9b78b44ae2ab8b819bf79433"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('MyEnviron': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
